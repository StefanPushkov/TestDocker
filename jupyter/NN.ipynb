{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils import data as data_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('E:/RTC/skill-task2/data/train.csv/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f1603</th>\n",
       "      <th>f1604</th>\n",
       "      <th>f1605</th>\n",
       "      <th>f1606</th>\n",
       "      <th>f1607</th>\n",
       "      <th>f1608</th>\n",
       "      <th>f1609</th>\n",
       "      <th>f1610</th>\n",
       "      <th>f1611</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_0</td>\n",
       "      <td>25.609375</td>\n",
       "      <td>6.703125</td>\n",
       "      <td>3.652344</td>\n",
       "      <td>10.039062</td>\n",
       "      <td>169.375</td>\n",
       "      <td>102.8125</td>\n",
       "      <td>1.422852</td>\n",
       "      <td>6.722656</td>\n",
       "      <td>8.015625</td>\n",
       "      <td>...</td>\n",
       "      <td>8.070312</td>\n",
       "      <td>4.363281</td>\n",
       "      <td>5.019531</td>\n",
       "      <td>5.710938</td>\n",
       "      <td>6.343750</td>\n",
       "      <td>6.843750</td>\n",
       "      <td>7.289062</td>\n",
       "      <td>7.617188</td>\n",
       "      <td>7.980469</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1</td>\n",
       "      <td>18.343750</td>\n",
       "      <td>5.824219</td>\n",
       "      <td>2.966797</td>\n",
       "      <td>4.902344</td>\n",
       "      <td>164.625</td>\n",
       "      <td>71.8125</td>\n",
       "      <td>1.357422</td>\n",
       "      <td>5.894531</td>\n",
       "      <td>2.753906</td>\n",
       "      <td>...</td>\n",
       "      <td>7.359375</td>\n",
       "      <td>4.195312</td>\n",
       "      <td>4.808594</td>\n",
       "      <td>5.425781</td>\n",
       "      <td>5.949219</td>\n",
       "      <td>6.339844</td>\n",
       "      <td>6.730469</td>\n",
       "      <td>7.074219</td>\n",
       "      <td>7.175781</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_2</td>\n",
       "      <td>28.562500</td>\n",
       "      <td>6.230469</td>\n",
       "      <td>3.583984</td>\n",
       "      <td>7.882812</td>\n",
       "      <td>159.500</td>\n",
       "      <td>113.1875</td>\n",
       "      <td>1.696289</td>\n",
       "      <td>6.316406</td>\n",
       "      <td>4.605469</td>\n",
       "      <td>...</td>\n",
       "      <td>8.562500</td>\n",
       "      <td>4.523438</td>\n",
       "      <td>5.097656</td>\n",
       "      <td>5.789062</td>\n",
       "      <td>6.457031</td>\n",
       "      <td>6.871094</td>\n",
       "      <td>7.386719</td>\n",
       "      <td>7.878906</td>\n",
       "      <td>8.328125</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_3</td>\n",
       "      <td>28.062500</td>\n",
       "      <td>6.132812</td>\n",
       "      <td>2.726562</td>\n",
       "      <td>6.378906</td>\n",
       "      <td>169.750</td>\n",
       "      <td>111.0000</td>\n",
       "      <td>1.535156</td>\n",
       "      <td>6.199219</td>\n",
       "      <td>3.712891</td>\n",
       "      <td>...</td>\n",
       "      <td>4.558594</td>\n",
       "      <td>3.533203</td>\n",
       "      <td>3.900391</td>\n",
       "      <td>4.261719</td>\n",
       "      <td>4.042969</td>\n",
       "      <td>3.869141</td>\n",
       "      <td>3.890625</td>\n",
       "      <td>4.042969</td>\n",
       "      <td>4.273438</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_4</td>\n",
       "      <td>20.109375</td>\n",
       "      <td>6.144531</td>\n",
       "      <td>3.203125</td>\n",
       "      <td>6.035156</td>\n",
       "      <td>164.750</td>\n",
       "      <td>78.8750</td>\n",
       "      <td>1.281250</td>\n",
       "      <td>6.187500</td>\n",
       "      <td>4.003906</td>\n",
       "      <td>...</td>\n",
       "      <td>6.613281</td>\n",
       "      <td>4.625000</td>\n",
       "      <td>4.996094</td>\n",
       "      <td>5.328125</td>\n",
       "      <td>5.593750</td>\n",
       "      <td>5.800781</td>\n",
       "      <td>6.027344</td>\n",
       "      <td>6.242188</td>\n",
       "      <td>6.449219</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  sample_id         f0        f1        f2         f3       f4        f5  \\\n",
       "0  sample_0  25.609375  6.703125  3.652344  10.039062  169.375  102.8125   \n",
       "1  sample_1  18.343750  5.824219  2.966797   4.902344  164.625   71.8125   \n",
       "2  sample_2  28.562500  6.230469  3.583984   7.882812  159.500  113.1875   \n",
       "3  sample_3  28.062500  6.132812  2.726562   6.378906  169.750  111.0000   \n",
       "4  sample_4  20.109375  6.144531  3.203125   6.035156  164.750   78.8750   \n",
       "\n",
       "         f6        f7        f8  ...     f1603     f1604     f1605     f1606  \\\n",
       "0  1.422852  6.722656  8.015625  ...  8.070312  4.363281  5.019531  5.710938   \n",
       "1  1.357422  5.894531  2.753906  ...  7.359375  4.195312  4.808594  5.425781   \n",
       "2  1.696289  6.316406  4.605469  ...  8.562500  4.523438  5.097656  5.789062   \n",
       "3  1.535156  6.199219  3.712891  ...  4.558594  3.533203  3.900391  4.261719   \n",
       "4  1.281250  6.187500  4.003906  ...  6.613281  4.625000  4.996094  5.328125   \n",
       "\n",
       "      f1607     f1608     f1609     f1610     f1611    y  \n",
       "0  6.343750  6.843750  7.289062  7.617188  7.980469  1.0  \n",
       "1  5.949219  6.339844  6.730469  7.074219  7.175781  1.0  \n",
       "2  6.457031  6.871094  7.386719  7.878906  8.328125  1.0  \n",
       "3  4.042969  3.869141  3.890625  4.042969  4.273438  1.0  \n",
       "4  5.593750  5.800781  6.027344  6.242188  6.449219  0.0  \n",
       "\n",
       "[5 rows x 1614 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['sample_id', 'y'], axis=1)\n",
    "y = data['y']\n",
    "\n",
    "# Split in train/test\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data normalization\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "scale_features_std = StandardScaler() \n",
    "X_train_std = scale_features_std.fit_transform(X_train) \n",
    "x_test_std = scale_features_std.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To torch tensor: Train\n",
    "X_train_tensor = torch.tensor(X_train_std, dtype=torch.float)\n",
    "Y_train_tensor = torch.tensor(Y_train.values).flatten() \n",
    "\n",
    "# Test\n",
    "x_test_tensor = torch.tensor(x_test_std, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.values).flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([876, 1612])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train dataset\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = data_utils.TensorDataset(X_train_tensor, Y_train_tensor) \n",
    "train_loader = data_utils.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1612])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "for data, labels in train_loader:\n",
    "    print(data.size())\n",
    "    print(labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([876, 1612])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "#our class must extend nn.Module\n",
    "class MyClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyClassifier,self).__init__()\n",
    "        #Our network consists of 3 layers. 1 input, 1 hidden and 1 output layer\n",
    "        #This applies Linear transformation to input data. \n",
    "        self.fc1 = nn.Linear(1612,3200)\n",
    "        self.fc2 = nn.Linear(3200,3200)\n",
    "        self.fc3 = nn.Linear(3200,1600)\n",
    "        \n",
    "        #This applies linear transformation to produce output data\n",
    "        self.fc4 = nn.Linear(1600,2)\n",
    "        \n",
    "        self.bn0 = nn.BatchNorm1d(1612)\n",
    "        self.bn1 = nn.BatchNorm1d(3200)\n",
    "        self.bn2 = nn.BatchNorm1d(3200)\n",
    "        self.bn3 = nn.BatchNorm1d(1600)\n",
    "        \n",
    "        \n",
    "    #This must be implemented\n",
    "    def forward(self,x):\n",
    "        #Output of the first layer\n",
    "        x = self.bn0(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.bn3(x)\n",
    "        \n",
    "        \n",
    "        #This produces output\n",
    "        \n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "        \n",
    "    #This function takes an input and predicts the class, (0 or 1)        \n",
    "    def predict(self,x):\n",
    "        #Apply softmax to output. \n",
    "        pred = F.softmax(self.forward(x))\n",
    "        ans = []\n",
    "        #Pick the class with maximum weight\n",
    "        for t in pred:\n",
    "            if t[0]>t[1]:\n",
    "                ans.append(0)\n",
    "            else:\n",
    "                ans.append(1)\n",
    "        return torch.tensor(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the model        \n",
    "model = MyClassifier()\n",
    "#Define loss criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyClassifier(\n",
       "  (fc1): Linear(in_features=1612, out_features=3200, bias=True)\n",
       "  (fc2): Linear(in_features=3200, out_features=3200, bias=True)\n",
       "  (fc3): Linear(in_features=3200, out_features=1600, bias=True)\n",
       "  (fc4): Linear(in_features=1600, out_features=2, bias=True)\n",
       "  (bn1): BatchNorm1d(3200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(3200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(1600, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optim, criterion, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        output = model(x)\n",
    "        loss = criterion(output, y.long())   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "        # print(\"Batch loss: \", batch*(loss.item()))\n",
    "    return sum_loss/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss 2.592891892341718\n",
      "Epoch 2, Loss 0.546780363881969\n",
      "Epoch 3, Loss 0.4888010246840786\n",
      "Epoch 4, Loss 0.41284526333416977\n",
      "Epoch 5, Loss 0.37902917410140713\n",
      "Epoch 6, Loss 0.32865289221071214\n",
      "Epoch 7, Loss 0.2953430107331167\n",
      "Epoch 8, Loss 0.25992762729457525\n",
      "Epoch 9, Loss 0.1943664913444214\n",
      "Epoch 10, Loss 0.16264918065506573\n",
      "Epoch 11, Loss 0.13211341038958668\n",
      "Epoch 12, Loss 0.10742723458705972\n",
      "Epoch 13, Loss 0.12470945719306327\n",
      "Epoch 14, Loss 0.100245250652642\n",
      "Epoch 15, Loss 0.13673679020306836\n"
     ]
    }
   ],
   "source": [
    "#Number of epochs\n",
    "epochs = 15\n",
    "#List to store losses\n",
    "losses = []\n",
    "for i in range(epochs):\n",
    "    epoch_loss = train_model(model=model, optim=optimizer, criterion=criterion, train_dl=train_loader)\n",
    "    losses.append(epoch_loss)\n",
    "    print(\"Epoch {0}, Loss {1}\".format(i+1, epoch_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs), losses)\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.68      0.71        82\n",
      "           1       0.82      0.86      0.84       137\n",
      "\n",
      "    accuracy                           0.79       219\n",
      "   macro avg       0.78      0.77      0.78       219\n",
      "weighted avg       0.79      0.79      0.79       219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program_Files\\Anaconda3\\envs\\stepik_mipt\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "y_preds = model.predict(x_test_tensor)\n",
    "print(metrics.classification_report(y_test_tensor.long(), y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7945205479452054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Program_Files\\Anaconda3\\envs\\stepik_mipt\\lib\\site-packages\\ipykernel_launcher.py:43: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(model.predict(x_test_tensor),y_test_tensor.long()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
