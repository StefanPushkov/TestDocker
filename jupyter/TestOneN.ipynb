{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom matplotlib import pyplot as plt\nimport xgboost as xgb\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.svm import LinearSVC\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier\n\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nfrom sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.svm import LinearSVC\n\nimport torch.nn.functional as F\nimport torch\nimport torch.nn as nn\nfrom torch.utils import data as data_utils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read data \ndf = pd.read_csv('../input/skill-task2/train.csv/train.csv')\ndf_test = pd.read_csv('../input/skill-task2/test.csv/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create copy of a dataframe\ndata = df.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get general information about the dataframe\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get basic statistical characteristics\ndata.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's look at statistics on non-numerical features. All values are unique.\ndata.describe(include=['object'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check label values\ndata['y'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if any columns are empty\ncol_names = data.columns\nfor col in col_names:\n    if data[col].empty:\n        print(f'DataFrame column {name} is empty!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check class distribution\nsns.countplot(data['y'],label=\"Sum\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace inf values with np.nan, then replace nan with 0\ndata.replace([np.inf, -np.inf], np.nan,inplace=True)\ndata = data.fillna(0) # Check mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if contains null values\ndata.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"All values are finite: \", np.all(np.isfinite(data.iloc[:,1:].head())))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Normalize features and split data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features\nX = data.drop(['sample_id', 'y'], axis=1)\n# Labels\ny = data['y']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Features normalization\nfeatures_norm = StandardScaler() \nX_std = features_norm.fit_transform(X) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split data in train/test\nX_train, x_test, Y_train, y_test = train_test_split(X_std, y, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Create torch tensors"},{"metadata":{"trusted":true},"cell_type":"code","source":"# To torch tensor: Train\nX_train_tensor = torch.tensor(X_train, dtype=torch.float)\nY_train_tensor = torch.tensor(Y_train.values).flatten() \n\n# Test\nx_test_tensor = torch.tensor(x_test, dtype=torch.float)\ny_test_tensor = torch.tensor(y_test.values).flatten() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train base models using cross-validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random forest classifier\nrf = RandomForestClassifier()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n\n# Train with cross_validation\nscores_rf = cross_validate(rf, X_std, y, scoring=scoring, cv=5)\n\nsorted(scores_rf.keys())\nforest_fit_time = scores_rf['fit_time'].mean()\nforest_score_time = scores_rf['score_time'].mean()\nforest_accuracy = scores_rf['test_accuracy'].mean()\nforest_precision = scores_rf['test_precision_macro'].mean()\nforest_recall = scores_rf['test_recall_macro'].mean()\nforest_f1 = scores_rf['test_f1_weighted'].mean()\nforest_roc = scores_rf['test_roc_auc'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost classifier\nxgb_clf = XGBClassifier()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n\n# Train with cross_validation\nscores_xgb = cross_validate(xgb_clf, X_std, y, scoring=scoring, cv=5)\n\nsorted(scores_xgb.keys())\nXGB_fit_time = scores_xgb['fit_time'].mean()\nXGB_score_time = scores_xgb['score_time'].mean()\nXGB_accuracy = scores_xgb['test_accuracy'].mean()\nXGB_precision = scores_xgb['test_precision_macro'].mean()\nXGB_recall = scores_xgb['test_recall_macro'].mean()\nXGB_f1 = scores_xgb['test_f1_weighted'].mean()\nXGB_roc = scores_xgb['test_roc_auc'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support vector machine\nSVM = SVC(probability = True)\n\nscoring = ['accuracy','precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n\n# Train with cross_validation\nscores_svm = cross_validate(SVM, X_std, y, scoring=scoring, cv=5)\n\nsorted(scores_svm.keys())\nSVM_fit_time = scores_svm['fit_time'].mean()\nSVM_score_time = scores_svm['score_time'].mean()\nSVM_accuracy = scores_svm['test_accuracy'].mean()\nSVM_precision = scores_svm['test_precision_macro'].mean()\nSVM_recall = scores_svm['test_recall_macro'].mean()\nSVM_f1 = scores_svm['test_f1_weighted'].mean()\nSVM_roc = scores_svm['test_roc_auc'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-Nearest Neighbors\nKNN = KNeighborsClassifier()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n\n# Train with cross_validation\nscores_knn = cross_validate(KNN, X_std, y, scoring=scoring, cv=5)\n\nsorted(scores_knn.keys())\nKNN_fit_time = scores_knn['fit_time'].mean()\nKNN_score_time = scores_knn['score_time'].mean()\nKNN_accuracy = scores_knn['test_accuracy'].mean()\nKNN_precision = scores_knn['test_precision_macro'].mean()\nKNN_recall = scores_knn['test_recall_macro'].mean()\nKNN_f1 = scores_knn['test_f1_weighted'].mean()\nKNN_roc = scores_knn['test_roc_auc'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparison of algorithms\nmodels_initial = pd.DataFrame({\n    'Model'       : ['Support Vector Machine', 'Random Forest', 'XGBClassifier', 'KNN'],\n    'Fitting time': [SVM_fit_time, forest_fit_time, XGB_fit_time, KNN_fit_time],\n    'Scoring time': [SVM_score_time, forest_score_time, XGB_score_time, KNN_score_time],\n    'Accuracy'    : [SVM_accuracy, forest_accuracy, XGB_accuracy, KNN_accuracy],\n    'Precision'   : [SVM_precision, forest_precision, XGB_precision, KNN_precision],\n    'Recall'      : [SVM_recall, forest_recall, XGB_recall, KNN_recall],\n    'F1_score'    : [SVM_f1, forest_f1, XGB_f1, KNN_f1],\n    'ROC_AUC'     : [SVM_roc, forest_roc, XGB_roc, KNN_roc],\n    }, columns = ['Model', 'Fitting time', 'Scoring time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'ROC_AUC'])\n\nmodels_initial.sort_values(by='ROC_AUC', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = models_initial.sort_values(by='ROC_AUC', ascending=False).plot.bar(x='Model', y='ROC_AUC', rot=30)\nax.set_ylabel(\"ROC_AUC\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recap: Random forest has the lowest accuracy, so we will not use it in stacking"},{"metadata":{},"cell_type":"markdown","source":"### Principal Component Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\npca = PCA()\npca.fit_transform(X_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"explained_variance=pca.explained_variance_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot individual explained variance over components \nplt.figure(figsize=(10, 6))\n\nplt.bar(range(len(explained_variance)), explained_variance, alpha=0.5, align='center',\n        label='individual explained variance')\nplt.ylabel('Explained variance ratio')\nplt.xlabel('Principal components')\nplt.legend(loc='best')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA(n_components=190)\npca.fit_transform(X_std)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Explained variance: %.4f' % pca.explained_variance_ratio_.sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can see that the 1st aprox 15 components retains more than 99% of the data.\n# Let us take only first 15 principal components and visualise it using K-means clustering\nX_std_pca = pca.fit_transform(X_std)\nplt.figure(figsize = (5,5))\nplt.scatter(X_std_pca[:,0],X_std_pca[:,1])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.cluster import KMeans\nkmeans = KMeans(n_clusters=2, random_state=5)\nX_clustered = kmeans.fit_predict(X_std_pca)\n\nLABEL_COLOR_MAP = {0 : 'g',\n                   1 : 'y'\n                  }\n\nlabel_color = [LABEL_COLOR_MAP[l] for l in X_clustered]\nplt.figure(figsize = (5,5))\nplt.scatter(X_std_pca[:,0],X_std_pca[:,1], c= label_color)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random forest classifier\nrf = RandomForestClassifier()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n\n# Train with cross_validation\nscores_rf = cross_validate(rf, X_std_pca, y, scoring=scoring, cv=5)\n\nsorted(scores_rf.keys())\nforest_fit_time = scores_rf['fit_time'].mean()\nforest_score_time = scores_rf['score_time'].mean()\nforest_accuracy = scores_rf['test_accuracy'].mean()\nforest_precision = scores_rf['test_precision_macro'].mean()\nforest_recall = scores_rf['test_recall_macro'].mean()\nforest_f1 = scores_rf['test_f1_weighted'].mean()\nforest_roc = scores_rf['test_roc_auc'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# XGBoost classifier\nxgb_clf = XGBClassifier()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n\n# Train with cross_validation\nscores_xgb = cross_validate(xgb_clf, X_std_pca, y, scoring=scoring, cv=5)\n\nsorted(scores_xgb.keys())\nXGB_fit_time = scores_xgb['fit_time'].mean()\nXGB_score_time = scores_xgb['score_time'].mean()\nXGB_accuracy = scores_xgb['test_accuracy'].mean()\nXGB_precision = scores_xgb['test_precision_macro'].mean()\nXGB_recall = scores_xgb['test_recall_macro'].mean()\nXGB_f1 = scores_xgb['test_f1_weighted'].mean()\nXGB_roc = scores_xgb['test_roc_auc'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Support vector machine\nSVM = SVC(probability = True)\n\nscoring = ['accuracy','precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n\n# Train with cross_validation\nscores_svm = cross_validate(SVM, X_std_pca, y, scoring=scoring, cv=5)\n\nsorted(scores_svm.keys())\nSVM_fit_time = scores_svm['fit_time'].mean()\nSVM_score_time = scores_svm['score_time'].mean()\nSVM_accuracy = scores_svm['test_accuracy'].mean()\nSVM_precision = scores_svm['test_precision_macro'].mean()\nSVM_recall = scores_svm['test_recall_macro'].mean()\nSVM_f1 = scores_svm['test_f1_weighted'].mean()\nSVM_roc = scores_svm['test_roc_auc'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# K-Nearest Neighbors\nKNN = KNeighborsClassifier()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\nscores_knn = cross_validate(KNN, X_std_pca, y, scoring=scoring, cv=5)\n\nsorted(scores_knn.keys())\nKNN_fit_time = scores_knn['fit_time'].mean()\nKNN_score_time = scores_knn['score_time'].mean()\nKNN_accuracy = scores_knn['test_accuracy'].mean()\nKNN_precision = scores_knn['test_precision_macro'].mean()\nKNN_recall = scores_knn['test_recall_macro'].mean()\nKNN_f1 = scores_knn['test_f1_weighted'].mean()\nKNN_roc = scores_knn['test_roc_auc'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparison of algorithms\nmodels_pca = pd.DataFrame({\n    'Model'       : ['Support Vector Machine', 'Random Forest', 'XGBClassifier', 'KNN'],\n    'Fitting time': [SVM_fit_time, forest_fit_time, XGB_fit_time, KNN_fit_time],\n    'Scoring time': [SVM_score_time, forest_score_time, XGB_score_time, KNN_score_time],\n    'Accuracy'    : [SVM_accuracy, forest_accuracy, XGB_accuracy, KNN_accuracy],\n    'Precision'   : [SVM_precision, forest_precision, XGB_precision, KNN_precision],\n    'Recall'      : [SVM_recall, forest_recall, XGB_recall, KNN_recall],\n    'F1_score'    : [SVM_f1, forest_f1, XGB_f1, KNN_f1],\n    'ROC_AUC'     : [SVM_roc, forest_roc, XGB_roc, KNN_roc],\n    }, columns = ['Model', 'Fitting time', 'Scoring time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'ROC_AUC'])\n\nmodels_pca.sort_values(by='ROC_AUC', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Auc has decreased after pca"},{"metadata":{},"cell_type":"markdown","source":"### Voting classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [SVC(probability = True), XGBClassifier(), RandomForestClassifier()]\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_ens = list(zip(['SVM', 'XGB', 'RF'], models))\nmodel_ens = VotingClassifier(estimators = models_ens, voting = 'soft')\nmodel_ens.fit(X_train, Y_train)\npred = model_ens.predict(x_test)\nprob_voting = model_ens.predict_proba(x_test)[:,1]\n\nacc_soft = accuracy_score(y_test, pred)\nprec_soft = precision_score(y_test, pred)\nrecall_soft = recall_score(y_test, pred)\nf1_soft = f1_score(y_test, pred)\nroc_auc_soft = roc_auc_score(y_test, prob_voting)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_ensembling = pd.DataFrame({\n    'Model'       : ['Ensembling_soft'],\n    'Accuracy'    : [acc_soft],\n    'Precision'   : [prec_soft],\n    'Recall'      : [recall_soft],\n    'F1_score'    : [f1_soft],\n    'ROC_AUC'     : [roc_auc_soft],\n    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'ROC_AUC'])\n\nmodels_ensembling.sort_values(by='ROC_AUC', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature selection using LinearSVC"},{"metadata":{"trusted":true},"cell_type":"code","source":"lsvc = LinearSVC().fit(X_train, Y_train)\nmodel = SelectFromModel(lsvc, prefit=True)\nX_train_svc = model.transform(X_train)\nX_train_svc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test_svc = model.transform(x_test)\nx_test_svc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = [SVC(probability = True), XGBClassifier(), RandomForestClassifier()]\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_ens_svc = list(zip(['SVM', 'XGB', 'KNN'], models))\nmodel_ens_svc = VotingClassifier(estimators = models_ens_svc, voting = 'soft')\nmodel_ens_svc.fit(X_train_svc, Y_train)\npred = model_ens_svc.predict(x_test_svc)\nprob = model_ens_svc.predict_proba(x_test_svc)[:,1]\n\nacc_soft = accuracy_score(y_test, pred)\nprec_soft = precision_score(y_test, pred)\nrecall_soft = recall_score(y_test, pred)\nf1_soft = f1_score(y_test, pred)\nroc_auc_soft = roc_auc_score(y_test, prob)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_ensembling_features_svc = pd.DataFrame({\n    'Model'       : ['Ensembling_soft'],\n    'Accuracy'    : [acc_soft],\n    'Precision'   : [prec_soft],\n    'Recall'      : [recall_soft],\n    'F1_score'    : [f1_soft],\n    'ROC_AUC'     : [roc_auc_soft],\n    }, columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'ROC_AUC'])\n\nmodels_ensembling_features_svc.sort_values(by='ROC_AUC', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### General comparison\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_general = pd.concat([models_initial['Model'], models_initial['ROC_AUC'], \n                           models_pca['Model'], models_pca['ROC_AUC'],\n                           models_ensembling['Model'], models_ensembling['ROC_AUC'],\n                           models_ensembling_features_svc['Model'], models_ensembling_features_svc['ROC_AUC']\n                           ]\n                          , axis=1)\n\nmodel_general.columns = ['Base models', 'AUC 1',\n                         'Models PCA', 'AUC 2',\n                         'Models ensembling', 'AUC 3',\n                        'Features sel. SVC (ensembl)', 'AUC 4']\n\nmodel_general.sort_values(by='AUC 1', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting ROC-AUC curve for voting classifier (AUC 3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, prob_voting)\nroc_auc = auc(false_positive_rate, true_positive_rate)\nroc_auc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.figure(figsize=(10,10))\nplt.title('Receiver Operating Characteristic')\nplt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\nplt.legend(loc = 'lower right')\nplt.plot([0, 1], [0, 1],linestyle='--')\nplt.axis('tight')\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission classic ML\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace inf values with np.nan, then replace nan with 0\ndf_test.replace([np.inf, -np.inf], np.nan,inplace=True)\ndf_test = df_test.fillna(0) \n\n# Features\nX_submission = df_test.drop(['sample_id'], axis=1)\n\nX_submission_std = features_norm.fit_transform(X_submission) \n\nansw = model_ens.predict_proba(X_submission_std)[:,1]\n\nsubmission = pd.DataFrame(df_test[\"sample_id\"], index=None)\nsubmission[\"y\"] = answ\nsubmission.to_csv(\"submission_voting_classifier.csv\", sep=\",\", index=False)\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Neural network"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create train dataloader\nbatch_size = 128\n\ntrain_dataset = data_utils.TensorDataset(X_train_tensor, Y_train_tensor) \ntrain_loader = data_utils.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n\n# Create eval dataloader\n\neval_dataset = data_utils.TensorDataset(x_test_tensor, y_test_tensor) \neval_loader = data_utils.DataLoader(dataset = eval_dataset, batch_size = batch_size, shuffle = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check batch sizes\nfor data, labels in eval_loader:\n    print(data.size())\n    print(labels.size())\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class must extend nn.Module\nclass MyClassifier(nn.Module):\n    def __init__(self):\n        super(MyClassifier,self).__init__()\n        # Our network consists of 3 layers. 1 input, 1 hidden and 1 output layer\n         \n        self.fc1 = nn.Linear(1612,200)\n        self.fc2 = nn.Linear(200,100)\n        self.layer_out = nn.Linear(100,1)\n        \n        self.dropout = nn.Dropout()\n        \n        \n        \n        self.bn0 = nn.BatchNorm1d(1612)\n        self.bn1 = nn.BatchNorm1d(200)\n        \n        self.bn_out = nn.BatchNorm1d(100)\n        \n        \n        \n    \n    def forward(self,x):\n        \n        # Batch normalization\n        x = self.bn0(x)\n        \n        # This applies Linear transformation to input data with non-linear activation\n        x = F.relu(self.fc1(x))\n        \n        # Dropout\n        x = self.dropout(x) \n        \n        x = self.bn1(x)\n        x = F.relu(self.fc2(x))\n        x = self.dropout(x) \n        \n        \n        x = self.bn_out(x)\n        #This applies linear transformation to produce output data\n        x = self.layer_out(x)\n        \n        return x\n        \n    \n    \n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Initialize the model        \nnetwork = MyClassifier()\n# Define loss criterion\ncriterion = nn.BCEWithLogitsLoss()\n# Define the optimizer\noptimizer = torch.optim.Adam(network.parameters(), lr=1e-3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"network","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, optim, criterion, train_dl):\n    model.train()\n    total = 0\n    sum_loss = 0\n    for x, y in train_dl:\n        batch = y.shape[0]\n        output = model(x)   \n        loss = criterion(output, y.unsqueeze(1))   \n        optim.zero_grad()\n        loss.backward()\n        \n        # Clip gradient \n        # torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n        optim.step()\n        \n        # Accumulate epoch loss \n        total += batch\n        sum_loss += batch*(loss.item())\n        # print(\"Batch loss: \", batch*(loss.item()))\n    return sum_loss/total","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#This function takes an input and predicts the class, (0 or 1)        \ndef predict(x, model):\n    with torch.no_grad():\n        y_pred = model(x)\n        y_pred_tag = torch.round(torch.sigmoid(y_pred))\n    return torch.tensor(y_pred_tag, dtype=float)\n\ndef predict_proba(x, model):\n    with torch.no_grad():\n        y_pred = model(x)\n        prob = torch.sigmoid(y_pred)    \n    return torch.tensor(prob, dtype=float)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Number of epochs\nepochs = 150\n#List to store losses\ntrain_losses = []\nfor i in range(epochs):\n    epoch_loss = train_model(model=network, optim=optimizer, criterion=criterion, train_dl=train_loader)\n    train_losses.append(epoch_loss)\n    if i % 10 == 0:\n        print(\"Epoch {0}, Loss {1}\".format(i+1, epoch_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(range(epochs), train_losses, label='Train loss')\nplt.ylabel('Loss')\nplt.xlabel('epoch');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"AUC \", roc_auc_score(y_test_tensor.long(), predict_proba(x_test_tensor, model=network)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission NN"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Replace inf values with np.nan, then replace nan with 0\ndf_test.replace([np.inf, -np.inf], np.nan,inplace=True)\ndf_test = df_test.fillna(0) \n\n# Features\nX_submission = df_test.drop(['sample_id'], axis=1)\n\nX_submission_std = features_norm.fit_transform(X_submission) \n\nX_submission_tensor = torch.tensor(X_submission_std, dtype=torch.float)\n\na = predict_proba(X_submission_tensor, model=network).numpy()\n\nsubmission_network = pd.DataFrame(df_test[\"sample_id\"], index=None)\nsubmission_network[\"y\"] = a\nsubmission_network.to_csv(\"submission_NN.csv\", sep=\",\", index=False)\nsubmission_network.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Recap: final submission - `submission_voting_classifier.csv` "},{"metadata":{},"cell_type":"markdown","source":"Stacking classic ml models => AUC = 89%+ Neural network =>"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}